# =============================================================================
# DSF Agent - Centralized Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values.
# This single file configures both Letta server and letta-code UI.
# The start.sh script will automatically distribute values to submodules.
#
# =============================================================================

# =============================================================================
# Required: Core API Keys
# =============================================================================

# Anthropic API Key - Required for Claude models
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI API Key - Optional for GPT models and DALL-E image generation
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# =============================================================================
# Letta Configuration
# =============================================================================

# Letta Base URL - Choose one:
# - For self-hosted (default): http://localhost:8283
# - For Letta Cloud: https://api.letta.com
LETTA_BASE_URL=http://localhost:8283

# Letta API Key - Only required if using Letta Cloud (not for self-hosted)
# Get from: https://app.letta.com/
# LETTA_API_KEY=sk-let-...

# =============================================================================
# Optional: Additional Model Providers
# =============================================================================

# Google/Gemini API Key - For Gemini models or Imagen image generation
# Get from: https://aistudio.google.com/apikey
# GOOGLE_API_KEY=AIza...
# Or use:
# GEMINI_API_KEY=AIza...

# Perplexity API Key - For Perplexity search/reasoning
# Get from: https://www.perplexity.ai/settings/api
# PERPLEXITY_API_KEY=pplx-...
# PERPLEXITY_TIMEOUT_MS=600000

# Ollama Base URL - For local Ollama models
# OLLAMA_BASE_URL=http://host.docker.internal:11434

# vLLM API Base - For vLLM models
# VLLM_API_BASE=http://host.docker.internal:8000

# Exa Search API Key - For Exa search capabilities
# EXA_API_KEY=your-exa-api-key-here

# =============================================================================
# Optional: Notion Publishing
# =============================================================================

# Notion Integration - For publishing stories to Notion
# See: letta-code/src/skills/builtin/publish-notion/README.md
# Get your token at: https://www.notion.so/my-integrations
# NOTION_TOKEN=secret_...

# Notion Database ID - Target database for story publishing
# Get from database URL: https://notion.so/workspace/DATABASE_ID?v=...
# NOTION_DATABASE_ID=...

# =============================================================================
# Optional: Development & Debug Flags
# =============================================================================

# Enable debug logging
# LETTA_DEBUG=1

# Disable telemetry (set to 0 or false)
# LETTA_CODE_TELEM=0

# Disable auto-updates
# DISABLE_AUTOUPDATER=1

# Debug auto-update process
# LETTA_DEBUG_AUTOUPDATE=1

# Debug Kitty protocol detection
# LETTA_DEBUG_KITTY=1
